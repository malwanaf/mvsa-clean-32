{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# diperoleh 160k siklus untuk satu kali inferensi dengan notebook sebelumnya"
      ],
      "metadata": {
        "id": "JlSLvrgp13Pc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SEL 0"
      ],
      "metadata": {
        "id": "kHzKH6UN15tU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-jppfXh1lcI",
        "outputId": "b05290db-aef0-4f73-e9ba-e6e93b89dcbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset already present.\n"
          ]
        }
      ],
      "source": [
        "# SEL 0: Download UCI-HAR dataset (jalankan sekali)\n",
        "import os, urllib.request, zipfile\n",
        "\n",
        "if not os.path.exists(\"UCI_HAR_Dataset\"):\n",
        "    print(\"Downloading UCI HAR dataset...\")\n",
        "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip\"\n",
        "    urllib.request.urlretrieve(url, \"UCI_HAR_Dataset.zip\")\n",
        "    with zipfile.ZipFile(\"UCI_HAR_Dataset.zip\", \"r\") as z:\n",
        "        z.extractall(\".\")\n",
        "    os.rename(\"UCI HAR Dataset\", \"UCI_HAR_Dataset\")\n",
        "    print(\"Dataset ready.\")\n",
        "else:\n",
        "    print(\"Dataset already present.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SEL A - Helper Functs"
      ],
      "metadata": {
        "id": "no-_iVLy19Ux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === SEL A (final clean exporter) ===\n",
        "import numpy as np, textwrap\n",
        "\n",
        "def pack_bits_2d(arr2d, word_size=8, bitorder='little'):\n",
        "    arr2d = np.asarray(arr2d, dtype=np.uint8)\n",
        "    n, D = arr2d.shape\n",
        "    if word_size == 8:\n",
        "        pad = (-D) % 8\n",
        "        if pad: arr2d = np.pad(arr2d, ((0,0),(0,pad)))\n",
        "        packed = np.packbits(arr2d, axis=-1, bitorder=bitorder).astype(np.uint8)\n",
        "        return packed\n",
        "    elif word_size == 16:\n",
        "        pad = (-D) % 16\n",
        "        if pad: arr2d = np.pad(arr2d, ((0,0),(0,pad)))\n",
        "        dim_word = arr2d.shape[1] // 16\n",
        "        bytes_ = np.packbits(arr2d.reshape(n, dim_word, 16), axis=-1, bitorder=bitorder)\n",
        "        out = (bytes_[...,0].astype(np.uint16) | (bytes_[...,1].astype(np.uint16) << 8))\n",
        "        return out\n",
        "    elif word_size == 32:\n",
        "        pad = (-D) % 32\n",
        "        if pad: arr2d = np.pad(arr2d, ((0,0),(0,pad)))\n",
        "        dim_word = arr2d.shape[1] // 32\n",
        "        bytes_ = np.packbits(arr2d.reshape(n, dim_word, 32), axis=-1, bitorder=bitorder)\n",
        "        out = (bytes_[...,0].astype(np.uint32) |\n",
        "               (bytes_[...,1].astype(np.uint32) << 8) |\n",
        "               (bytes_[...,2].astype(np.uint32) << 16) |\n",
        "               (bytes_[...,3].astype(np.uint32) << 24))\n",
        "        return out\n",
        "    else:\n",
        "        raise ValueError(\"word_size must be 8/16/32\")\n",
        "\n",
        "def _flat_c_body(arr, per_line=16):\n",
        "    flat = arr.flatten()\n",
        "    rows = []\n",
        "    for i in range(0, len(flat), per_line):\n",
        "        rows.append(\", \".join(str(int(x)) for x in flat[i:i+per_line]))\n",
        "    return \",\\n    \".join(rows)\n",
        "\n",
        "def write_model_files(packed_F, packed_V, packed_C, word_size, hv_dim_bit, num_quant, prefix=\"model\"):\n",
        "    dim_word = packed_F.shape[1]\n",
        "    n_features = packed_F.shape[0]\n",
        "    n_classes = packed_C.shape[0]\n",
        "\n",
        "    dtype = {8:\"uint8_t\",16:\"uint16_t\",32:\"uint32_t\"}[word_size]\n",
        "\n",
        "    # === model.h ===\n",
        "    model_h = f\"\"\"#ifndef MODEL_MODEL_H_\n",
        "#define MODEL_MODEL_H_\n",
        "\n",
        "#include <stdint.h>\n",
        "\n",
        "#define MICROVSA_MODEL_FHV_DIMENSION_BIT {hv_dim_bit}\n",
        "#define MICROVSA_MODEL_FHV_DIMENSION_WORD {dim_word}\n",
        "#define MICROVSA_MODEL_NUM_CLASS {n_classes}\n",
        "#define MICROVSA_MODEL_NUM_FEATURE {n_features}\n",
        "#define MICROVSA_MODEL_NUM_QUANT {num_quant}\n",
        "#define MICROVSA_MODEL_DTYPE {dtype}\n",
        "\n",
        "#ifdef MODEL_C_IN_RAM\n",
        "#define MODEL_C_QUALIFIER\n",
        "#else\n",
        "#define MODEL_C_QUALIFIER const\n",
        "#endif\n",
        "#ifdef MODEL_F_IN_RAM\n",
        "#define MODEL_F_QUALIFIER\n",
        "#else\n",
        "#define MODEL_F_QUALIFIER const\n",
        "#endif\n",
        "#ifdef MODEL_V_IN_RAM\n",
        "#define MODEL_V_QUALIFIER\n",
        "#else\n",
        "#define MODEL_V_QUALIFIER const\n",
        "#endif\n",
        "\n",
        "extern MODEL_C_QUALIFIER {dtype} MICROVSA_MODEL_C[];\n",
        "extern MODEL_F_QUALIFIER {dtype} MICROVSA_MODEL_F[];\n",
        "extern MODEL_V_QUALIFIER {dtype} MICROVSA_MODEL_V[];\n",
        "\n",
        "#endif // MODEL_MODEL_H_\n",
        "\"\"\"\n",
        "    with open(f\"{prefix}.h\",\"w\") as fh: fh.write(model_h)\n",
        "\n",
        "    # === model.c ===\n",
        "    flatC = _flat_c_body(packed_C)\n",
        "    flatF = _flat_c_body(packed_F)\n",
        "    flatV = _flat_c_body(packed_V)\n",
        "    c_text = f'#include \"{prefix}.h\"\\n\\n'\n",
        "    c_text += f\"MODEL_C_QUALIFIER {dtype} MICROVSA_MODEL_C[] = {{\\n    {flatC}\\n}};\\n\\n\"\n",
        "    c_text += f\"MODEL_F_QUALIFIER {dtype} MICROVSA_MODEL_F[] = {{\\n    {flatF}\\n}};\\n\\n\"\n",
        "    c_text += f\"MODEL_V_QUALIFIER {dtype} MICROVSA_MODEL_V[] = {{\\n    {flatV}\\n}};\\n\\n\"\n",
        "    with open(f\"{prefix}.c\",\"w\") as fc: fc.write(c_text)\n",
        "    print(\"Wrote\", f\"{prefix}.h/.c\")\n",
        "\n",
        "def write_params(min_val, inv_range, scale=4096, fname=\"model_params_scaled.h\"):\n",
        "    header = textwrap.dedent(f\"\"\"\\\n",
        "    #ifndef MODEL_PARAMS_SCALED_H_\n",
        "    #define MODEL_PARAMS_SCALED_H_\n",
        "    #include <stdint.h>\n",
        "    #define FIXED_POINT_SCALE_FACTOR {scale}\n",
        "\n",
        "    \"\"\")\n",
        "    def arr_to_c(name, arr, dtype=\"int32_t\"):\n",
        "        rows=[]\n",
        "        for i in range(0, len(arr), 16):\n",
        "            rows.append(\", \".join(str(int(x)) for x in arr[i:i+16]))\n",
        "        body = \",\\n    \".join(rows)\n",
        "        return f\"const {dtype} {name}[{len(arr)}] = {{\\n    {body}\\n}};\\n\\n\"\n",
        "    header += arr_to_c(\"min_val_scaled\", min_val, \"int32_t\")\n",
        "    header += arr_to_c(\"inv_range_val_scaled\", inv_range, \"int32_t\")\n",
        "    header += \"#endif // MODEL_PARAMS_SCALED_H_\\n\"\n",
        "    with open(fname,\"w\") as f: f.write(header)\n",
        "    print(\"Wrote\", fname)\n",
        "\n",
        "def write_test_data(sample, label, prefix=\"test_data\"):\n",
        "    h_code = f\"\"\"#ifndef TEST_DATA_H_\n",
        "#define TEST_DATA_H_\n",
        "#include <stdint.h>\n",
        "#define TEST_DATA_SAMPLE_LENGTH {len(sample)}\n",
        "extern const float {prefix}_sample[];\n",
        "extern const uint8_t {prefix}_actual_label;\n",
        "#endif // TEST_DATA_H_\n",
        "\"\"\"\n",
        "    # fixed: no stray '\\' anymore\n",
        "    c_code = f'#include \"{prefix}.h\"\\n\\n'\n",
        "    c_code += f\"const uint8_t {prefix}_actual_label = {label};\\n\\n\"\n",
        "    rows=[]\n",
        "    for i in range(0,len(sample),8):\n",
        "        rows.append(\"    \" + \", \".join(f\"{x:.8f}f\" for x in sample[i:i+8]))\n",
        "    c_code += f\"const float {prefix}_sample[TEST_DATA_SAMPLE_LENGTH] = {{\\n\" + \",\\n\".join(rows) + \"\\n};\\n\"\n",
        "    with open(f\"{prefix}.h\",\"w\") as fh: fh.write(h_code)\n",
        "    with open(f\"{prefix}.c\",\"w\") as fc: fc.write(c_code)\n",
        "    print(\"Wrote\", f\"{prefix}.h/.c\")\n",
        "\n",
        "def write_microvsa_config(word_size, hv_dim_bit, n_classes, max_fhv_dim=None, fname=\"microvsa_config.h\"):\n",
        "    if max_fhv_dim is None:\n",
        "        max_fhv_dim = hv_dim_bit // word_size\n",
        "    text = f\"\"\"#ifndef MICROVSA_CONFIG_H_\n",
        "#define MICROVSA_CONFIG_H_\n",
        "\n",
        "#define MICROVSA_IMPL_WORDSIZE {word_size}\n",
        "#define MICROVSA_TMP_DTYPE uint{word_size}_t\n",
        "#define MICROVSA_ACC_DTYPE int32_t\n",
        "#define MICROVSA_MAX_NUM_CLASS {n_classes}\n",
        "#define MICROVSA_MAX_FHV_DIM {max_fhv_dim}\n",
        "#define MICROVSA_MAX_FHV_DIM_BIT {hv_dim_bit}\n",
        "#define MICROVSA_IMPL MICROVSA_IMPL_MCU_OPT_CC\n",
        "\n",
        "// keep large arrays in flash\n",
        "// #define MODEL_F_IN_RAM\n",
        "// #define MODEL_V_IN_RAM\n",
        "// #define MODEL_C_IN_RAM\n",
        "\n",
        "#endif // MICROVSA_CONFIG_H_\n",
        "\"\"\"\n",
        "    with open(fname,\"w\") as f: f.write(text)\n",
        "    print(\"Wrote\", fname)\n",
        "\n",
        "def export_all_from_bits(F_bits, V_bits, C_bits, feat_min, feat_range, test_sample, test_label, word_size=32, scale=4096):\n",
        "    hv_dim_bit = F_bits.shape[1]\n",
        "    num_quant = V_bits.shape[0]\n",
        "    packed_F = pack_bits_2d(F_bits, word_size=word_size)\n",
        "    packed_V = pack_bits_2d(V_bits, word_size=word_size)\n",
        "    packed_C = pack_bits_2d(C_bits, word_size=word_size)\n",
        "\n",
        "    write_model_files(packed_F, packed_V, packed_C, word_size, hv_dim_bit, num_quant, prefix=\"model\")\n",
        "\n",
        "    min_val_scaled = np.floor(feat_min * scale).astype(np.int32)\n",
        "    inv_range_val_scaled = np.round((1.0/np.maximum(feat_range,1e-8)) * scale).astype(np.int32)\n",
        "    write_params(min_val_scaled, inv_range_val_scaled, scale=scale)\n",
        "\n",
        "    write_test_data(test_sample, test_label, prefix=\"test_data\")\n",
        "    write_microvsa_config(word_size, hv_dim_bit, C_bits.shape[0])\n",
        "\n",
        "    print(\"Export complete.\")\n"
      ],
      "metadata": {
        "id": "ras2hap1119Z"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SEL 1"
      ],
      "metadata": {
        "id": "YDqjCkfh2EOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SEL 1: Train DiffLDC (safe mem) and extract F_bits,V_bits,C_bits\n",
        "import numpy as np, torch, torch.nn as nn, torch.optim as optim, os\n",
        "\n",
        "# load\n",
        "def load_uci_har(split='train'):\n",
        "    path = os.path.join(\"UCI_HAR_Dataset\", split, f\"X_{split}.txt\")\n",
        "    ypath = os.path.join(\"UCI_HAR_Dataset\", split, f\"y_{split}.txt\")\n",
        "    X = np.loadtxt(path).astype(np.float32)\n",
        "    y = (np.loadtxt(ypath).astype(int) - 1).astype(np.int64)\n",
        "    return X, y\n",
        "\n",
        "X_train, y_train = load_uci_har('train')\n",
        "X_test, y_test = load_uci_har('test')\n",
        "n_features = X_train.shape[1]\n",
        "n_classes = int(max(y_train.max(), y_test.max()) + 1)\n",
        "print(\"Shapes:\", X_train.shape, X_test.shape, \"n_classes\", n_classes)\n",
        "\n",
        "# hyperparams (tune these)\n",
        "NUM_QUANT = 256      # reduce to 64/128 to shrink model V size\n",
        "HV_DIM = 256         # try 128/256 per flash budget\n",
        "WORD = 32            # target word-size for ESP32\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", DEVICE)\n",
        "\n",
        "# quantization helpers\n",
        "feat_min = np.vstack([X_train, X_test]).min(axis=0)\n",
        "feat_max = np.vstack([X_train, X_test]).max(axis=0)\n",
        "feat_range = np.maximum(feat_max - feat_min, 1e-8)\n",
        "def quantize_array(X, num_quant=NUM_QUANT):\n",
        "    norm = (X - feat_min) / feat_range\n",
        "    return np.clip((norm * (num_quant - 1)).astype(int), 0, num_quant - 1)\n",
        "\n",
        "Xq_train = quantize_array(X_train)\n",
        "Xq_test  = quantize_array(X_test)\n",
        "\n",
        "# DiffLDC model\n",
        "class DiffLDC(nn.Module):\n",
        "    def __init__(self, n_features, num_quant, hv_dim, n_classes):\n",
        "        super().__init__()\n",
        "        self.V_embed = nn.Parameter(torch.randn(num_quant, hv_dim) * 0.01)\n",
        "        self.F = nn.Parameter(torch.randn(n_features, hv_dim) * 0.01)\n",
        "        self.C = nn.Parameter(torch.randn(n_classes, hv_dim) * 0.01)\n",
        "    def forward(self, quantized_samples):\n",
        "        Vvals = self.V_embed[quantized_samples]   # (B, n_features, hv_dim)\n",
        "        F = self.F.unsqueeze(0)\n",
        "        bound = Vvals * F\n",
        "        agg = bound.sum(dim=1)\n",
        "        agg_t = torch.tanh(agg)\n",
        "        Cnorm = torch.tanh(self.C)\n",
        "        logits = torch.matmul(agg_t, Cnorm.t())\n",
        "        return logits, agg_t\n",
        "\n",
        "train_x = torch.from_numpy(Xq_train).long().to(DEVICE)\n",
        "train_y = torch.from_numpy(y_train).long().to(DEVICE)\n",
        "test_x  = torch.from_numpy(Xq_test).long().to(DEVICE)\n",
        "test_y  = torch.from_numpy(y_test).long().to(DEVICE)\n",
        "\n",
        "model = DiffLDC(n_features, NUM_QUANT, HV_DIM, n_classes).to(DEVICE)\n",
        "opt = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-6)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "EPOCHS = 5\n",
        "BATCH = 64\n",
        "def eval_split(x_tensor, y_tensor, batch_size=256):\n",
        "    model.eval()\n",
        "    correct = 0; total = 0\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(x_tensor), batch_size):\n",
        "            xb = x_tensor[i:i+batch_size]\n",
        "            yb = y_tensor[i:i+batch_size]\n",
        "            logits, _ = model(xb)\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            correct += (preds == yb).sum().item()\n",
        "            total += len(yb)\n",
        "    return correct/total\n",
        "\n",
        "print(\"Training...\")\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    perm = np.random.permutation(len(train_x))\n",
        "    for i in range(0, len(train_x), BATCH):\n",
        "        idx = perm[i:i+BATCH]\n",
        "        xb = train_x[idx]; yb = train_y[idx]\n",
        "        opt.zero_grad()\n",
        "        logits, _ = model(xb)\n",
        "        loss = criterion(logits, yb)\n",
        "        loss.backward(); opt.step()\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} loss={loss.item():.4f} tr_acc={eval_split(train_x,train_y):.4f} te_acc={eval_split(test_x,test_y):.4f}\")\n",
        "\n",
        "# extract bipolar -> bits\n",
        "with torch.no_grad():\n",
        "    F_cont = torch.tanh(model.F).cpu().numpy()\n",
        "    V_cont = torch.tanh(model.V_embed).cpu().numpy()\n",
        "    C_cont = torch.tanh(model.C).cpu().numpy()\n",
        "\n",
        "F_bits = (F_cont > 0).astype(np.uint8)\n",
        "V_bits = (V_cont > 0).astype(np.uint8)\n",
        "C_bits = (C_cont > 0).astype(np.uint8)\n",
        "\n",
        "# save bits for reproducibility\n",
        "np.savez(\"ldc_trained_model_bits.npz\", F_bits=F_bits, V_bits=V_bits, C_bits=C_bits)\n",
        "print(\"Saved ldc_trained_model_bits.npz\", F_bits.shape, V_bits.shape, C_bits.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oA4fwAXA2B1H",
        "outputId": "54c1131f-063a-4eaf-c588-890477b0828e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes: (7352, 561) (2947, 561) n_classes 6\n",
            "Device: cpu\n",
            "Training...\n",
            "Epoch 1/5 loss=0.5974 tr_acc=0.8044 te_acc=0.7855\n",
            "Epoch 2/5 loss=0.0922 tr_acc=0.9705 te_acc=0.9264\n",
            "Epoch 3/5 loss=0.0575 tr_acc=0.9852 te_acc=0.9342\n",
            "Epoch 4/5 loss=0.1000 tr_acc=0.9918 te_acc=0.9338\n",
            "Epoch 5/5 loss=0.0238 tr_acc=0.9989 te_acc=0.9393\n",
            "Saved ldc_trained_model_bits.npz (561, 256) (256, 256) (6, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SEL 2"
      ],
      "metadata": {
        "id": "s6ZM9lgj2H0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SEL 2: Export (use bits saved from SEL1)\n",
        "import numpy as np, os\n",
        "d = np.load(\"ldc_trained_model_bits.npz\")\n",
        "F_bits = d[\"F_bits\"]; V_bits = d[\"V_bits\"]; C_bits = d[\"C_bits\"]\n",
        "# feat_min & feat_range must match quantization step in SEL1\n",
        "# If SEL1 variables still in memory, reuse feat_min, feat_range; otherwise recompute:\n",
        "# Recompute from dataset:\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "X_train = np.loadtxt(\"UCI_HAR_Dataset/train/X_train.txt\").astype(np.float32)\n",
        "X_test  = np.loadtxt(\"UCI_HAR_Dataset/test/X_test.txt\").astype(np.float32)\n",
        "feat_min = np.vstack([X_train, X_test]).min(axis=0)\n",
        "feat_max = np.vstack([X_train, X_test]).max(axis=0)\n",
        "feat_range = np.maximum(feat_max - feat_min, 1e-8)\n",
        "\n",
        "# pick test sample\n",
        "y_test = np.loadtxt(\"UCI_HAR_Dataset/test/y_test.txt\").astype(int) - 1\n",
        "X_test_all = X_test\n",
        "test_idx = 0\n",
        "test_sample = X_test_all[test_idx]\n",
        "test_label = int(y_test[test_idx])\n",
        "\n",
        "# call exporter (Sel A function)\n",
        "# choose word_size = 32 for ESP32\n",
        "from __main__ import export_all_from_bits\n",
        "export_all_from_bits(F_bits, V_bits, C_bits, feat_min, feat_range, test_sample, test_label, word_size=32, scale=4096)\n",
        "\n",
        "# will write: model.h, model.c, model_params_scaled.h, test_data.h, test_data.c\n",
        "print(\"Files written to notebook working directory.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocnkwily2FN2",
        "outputId": "eb1c18c7-7e3e-4a90-d786-0fe84d122982"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote model.h/.c\n",
            "Wrote model_params_scaled.h\n",
            "Wrote test_data.h/.c\n",
            "Wrote microvsa_config.h\n",
            "Export complete.\n",
            "Files written to notebook working directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SEL 3 - Quick Validation"
      ],
      "metadata": {
        "id": "Qil63W6d2LHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SEL 3: quick Python check (simple binary LDC emulate)\n",
        "import numpy as np\n",
        "d = np.load(\"ldc_trained_model_bits.npz\")\n",
        "F_bits = d[\"F_bits\"]; V_bits = d[\"V_bits\"]; C_bits = d[\"C_bits\"]\n",
        "# quantize the test sample with feat_min/feat_range\n",
        "test_sample_q = np.clip(((test_sample - feat_min)/feat_range * (V_bits.shape[0]-1)).astype(int),0,V_bits.shape[0]-1)\n",
        "# build S: for each feature do XOR(V[q], F[i]) then majority over features\n",
        "HV = F_bits.shape[1]\n",
        "S = np.zeros(HV, dtype=int)\n",
        "for i in range(F_bits.shape[0]):\n",
        "    vf = np.bitwise_xor(V_bits[test_sample_q[i]], F_bits[i])\n",
        "    S += (vf==1).astype(int)\n",
        "S_bit = (S > (F_bits.shape[0]//2)).astype(np.uint8)\n",
        "# compare to classes\n",
        "best=None; bestscore=1e9\n",
        "for k in range(C_bits.shape[0]):\n",
        "    # Hamming distance\n",
        "    h = np.count_nonzero(S_bit ^ C_bits[k])\n",
        "    if h < bestscore:\n",
        "        bestscore=h; best=k\n",
        "print(\"Python emu predict\", best, \"label\", test_label, \"hamming\", bestscore)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KOpghN62IsC",
        "outputId": "d64f3144-3b16-4cc6-c462-ebab7394d0bd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python emu predict 0 label 4 hamming 48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "55BvdJiP2N9l"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}
